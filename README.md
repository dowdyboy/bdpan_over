# 百度网盘AI大赛——图像处理挑战赛：文档图片去遮挡  B榜第8名方案
> 这是一个基于PaddlePaddle的文档图像去遮挡的解决方案，本方案在B榜上取得了第8名的成绩，本文将介绍本方案的一些细节，以及如何使用本方案进行预测。

## 项目描述
人们在使用手机等移动设备扫描证件或者扫描文档、
拍摄展示资料的场景中，
经常会拍摄到一些手指或者人头等其他因素，
对扫描成品的美观和易用性产生了影响。
通过技术对给定文档图像进行处理，
可以帮助人们去除文档图像中的手指、人头等因素，
还原真实的文档资料，提升使用效率。
本方案使用了基于CNN网络，通过对输入图像进行不同层的特征提取，然后，
通过解码器来进行图像恢复，最终实现图像去遮挡的任务。


## 项目结构
```
-|bdpan_over
-|checkpoint
-|dataset
-|dowdyboy_lib
-|scripts
-train_cls.py
-train_restore.pyss
-predict.py
```
- bdpan_over: 本项目的模型源代码
- checkpoint: 本项目的模型参数
- dataset: 本项目的数据集
- dowdyboy_lib: 自行编写的基于飞桨的深度学习训练器，详见[这里](https://github.com/dowdyboy/dowdyboy_lib)
- scripts: 本项目的历史版本
- train_cls.py: 训练脚本，用于训练判断是否包含遮挡的分类器
- train_restore.py: 训练脚本，用于训练去遮挡模型
- predict.py: 预测脚本

## 数据

本项目训练数据和验证数据由以下组成：

- images：文档图像，不包含遮挡
- patches：遮挡图像

本项目测试数据由百度网盘AI大赛提供，详见[官网](https://aistudio.baidu.com/aistudio/competition/detail/479/0/leaderboard) 。

训练验证数据 下载：

链接：https://pan.baidu.com/s/1qIezEi7BTAI3bX8_lkIh3g?pwd=dn4r 
提取码：dn4r

权重文件 下载: 

链接：https://pan.baidu.com/s/1pwSRYv--2756zDOO_O1cCg?pwd=8zdz 
提取码：8zdz

## 训练
> 将数据集放在dataset文件夹下；
```
|dataset
-|images
-|patches
```
> 将权重文件放在checkpoint文件夹下；
```
|checkpoint
-|pretrain
-|v4
```
> 运行train_cls脚本
```
python ./train_cls.py 
            --train-data-dir 
            ./dataset/ 
            --val-data-dir
            ./dataset/ 
            --use-scheduler 
            --use-warmup 
            --epoch 1000 
            --batch-size 4 
            --out-dir output_cls_v4
            --sync-bn
```
> 运行train_restore脚本
```
python ./train_restore.py 
            --train-data-dir 
            ./dataset/ 
            --val-data-dir
            ./dataset/ 
            --use-scheduler 
            --use-warmup 
            --epoch 1000 
            --batch-size 4 
            --out-dir output_restore_v4
            --sync-bn
```
> 竞赛时，我们使用了2卡RTX3090Ti进行了训练；

## 预测
> 运行predict.py脚本
```
python predict.py 
     <要预测的图像文件夹路径> results
```

## 项目详情

### 数据处理

通过观察A榜训练集和测试集，我们发现，训练集样本数量较少，初步思考，觉得这将产生过拟合从而一定程度上导致训练效果不佳。另外，因为训练集给出了遮挡的掩码图片，我们据此，首先根据掩码图片，将遮挡部分切剪出来，并对背景做透明化处理。同时将GT单独拿出来，使得文档背景和遮挡图片分离。
这样做的好处是，可以在训练阶段，动态的将遮挡覆盖到原图上，从而丰富训练集，一定程度上缓解过拟合问题。同时，需要注意的是，随机生成的训练图像也需要满足一定的约束，例如，手部遮挡必须出现在图像的编译区域、人像遮挡需要出现在图像底部区域，这就需要在代码中做特化处理。
同时在以上处理的基础上，我们还在数据处理管道中增加了诸如反转、光度变化等数据增强策略，以进一步提升训练数据的丰富性。
在输入时，我们先将图像缩放到520/1024大小，然后在进行一次大小为512*512或1024*1024随机裁切。在数据增强方面，只是简单采用了一定概率的水平翻转、光度变换以及遮挡图片的约束反转。
完成这些预处理后，将数据转换为0-1的Tensor，输入网络。

数据源比较复杂，所以我们设计了代码实现依概率随机采样，使得输入数据的来源尽量均衡。另外，采用了通过配置来确定数据量大小的方式，防止单次epoch训练时间过长。
另外，由于遮挡区域只占据整张图片的一小部分，因此，如果单纯随机裁切可能会导致正负样本不均衡，综上，我们设计了“密集裁切”策略，即根据裁切结果中包含遮挡部分的比率，来决定是否接纳裁切结果。


### 网络设计

我们的方案选择了shufflenetv2作为基础，其论文为：https://arxiv.org/abs/1807.11164  。

一方面，作为一种轻量化网络，它很适合当前赛题；另一方面，paddle框架对它有多种尺寸的预训练模型。

我们都知道，不同尺寸的模型能够提取不同的特征，这些特征有可能是互补关系，可以相互辅助实现更好的性能。

基于这样的思考，我们尝试放弃采用大个儿的单个模型，转而采用多个较小模型的合作。在最终的方案中，我们分别使用了一个shufflenet_v2_x0_5、shufflenet_v2_x0_33、shufflenet_v2_x0_25，组成了我们最终的网络。其中shufflenet_v2_x0_5使用relu作为激活函数，其余使用swish作为激活函数。

相对于采用单个模型，每一个分支模型都可以从不同的角度进行特征提取，可以一定程度上促进性能的提升。

然而，由于不同尺寸模型的中间特征图通道数不一，需要有一种方法进行统一转化。对此，我们设计了SqueezeExpandLayer，采用可分离卷积+分组输出的设计，在保证了性能的同时，尽可能的保留原始特征图中的多样化特征。SqueezeExpandLayer，首先采用一个深度卷积在空间上进行特征转化，而后采用多组点卷积从不同测度提取通道方面的特征，最终的输出为所有点卷积输出的拼接。

通过SqueezeExpandLayer，就可以将不同层的通道数进行统一，这样，中间特征图的通道数和尺寸就都一样了，我们就在此基础上使用“加和”作为中间特征图的融合方式。已经得到了融合的中间特征图，只需要设计一个下采样模块对不同层次的融合特征图进行再次融合，这样就能在深层特征图的基础上兼顾浅层特征图。为此，我们设计了DownSampleConvLayer，它使用MaxPool2D作为下采样方式，同时，在下采样之前，使用了残差卷积做了中间的特征提取。

对于上采样解码器，我们采用了相对于编码器更加简约的方式，使用SqueezeExpandLayer配合反卷积来实现了对图像的还原。总体设计上，使用了重量化的编码器和轻量化的解码器。

### 训练方案

在我们的方案中，我们配置训练数据个数为5000，验证数据个数为50，在2卡3090上进行1000 epoch个训练，取在验证集上psnr最高的模型为最优模型。
